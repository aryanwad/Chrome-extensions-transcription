#!/usr/bin/env python3
"""
Stream Processor for Live Transcription Catch-Up
Handles stream analysis and clip creation from various platforms
"""

import asyncio
import aiohttp
import logging
import time
from typing import List, Dict, Optional
from datetime import datetime, timedelta
import subprocess
import tempfile
import os

logger = logging.getLogger(__name__)

class StreamProcessor:
    """
    Processes live streams to extract audio segments for transcription
    """
    
    def __init__(self):
        self.session: Optional[aiohttp.ClientSession] = None
        self.temp_dir = tempfile.gettempdir()
        
    async def create_parallel_clips(self, stream_url: str, duration_minutes: int) -> List[Dict]:
        """
        Create multiple clips from a live stream in parallel
        """
        logger.info(f"üé¨ CLIP CREATION: {stream_url} ({duration_minutes}min)")
        
        platform = self._detect_platform(stream_url)
        
        if platform == "twitch":
            return await self._create_twitch_clips(stream_url, duration_minutes)
        elif platform == "youtube":
            return await self._create_youtube_clips(stream_url, duration_minutes)
        elif platform == "kick":
            return await self._create_kick_clips(stream_url, duration_minutes)
        else:
            raise Exception(f"Unsupported platform: {platform}")
    
    def _detect_platform(self, url: str) -> str:
        """Detect streaming platform from URL"""
        if "twitch.tv" in url:
            return "twitch"
        elif "youtube.com" in url or "youtu.be" in url:
            return "youtube"
        elif "kick.com" in url:
            return "kick"
        else:
            return "unknown"
    
    async def _create_twitch_clips(self, stream_url: str, duration_minutes: int) -> List[Dict]:
        """
        Create clips from Twitch stream using mock data for demo
        In production, this would use Twitch API or yt-dlp
        """
        logger.info(f"üü£ TWITCH PROCESSING: {stream_url}")
        
        # Mock clip creation for demo
        clips = []
        clips_needed = max(1, duration_minutes // 10)  # 1 clip per 10 minutes
        
        for i in range(clips_needed):
            # Simulate clip creation delay
            await asyncio.sleep(0.5)
            
            clip = {
                "id": f"twitch_clip_{i}_{int(time.time())}",
                "platform": "twitch",
                "url": stream_url,
                "start_time": i * 600,  # 10 minutes apart
                "duration": min(600, (duration_minutes - i * 10) * 60),  # Up to 10 minutes each
                "created_at": datetime.now().isoformat(),
                "audio_file": await self._mock_extract_audio(stream_url, i)
            }
            clips.append(clip)
            logger.info(f"‚úÖ CLIP CREATED: {clip['id']} ({clip['duration']}s)")
        
        return clips
    
    async def _create_youtube_clips(self, stream_url: str, duration_minutes: int) -> List[Dict]:
        """
        Create clips from YouTube stream
        """
        logger.info(f"üî¥ YOUTUBE PROCESSING: {stream_url}")
        
        # For demo, create mock clips
        clips = []
        clips_needed = max(1, duration_minutes // 15)  # 1 clip per 15 minutes
        
        for i in range(clips_needed):
            await asyncio.sleep(0.3)
            
            clip = {
                "id": f"youtube_clip_{i}_{int(time.time())}",
                "platform": "youtube",
                "url": stream_url,
                "start_time": i * 900,  # 15 minutes apart
                "duration": min(900, (duration_minutes - i * 15) * 60),
                "created_at": datetime.now().isoformat(),
                "audio_file": await self._mock_extract_audio(stream_url, i)
            }
            clips.append(clip)
            logger.info(f"‚úÖ CLIP CREATED: {clip['id']} ({clip['duration']}s)")
        
        return clips
    
    async def _create_kick_clips(self, stream_url: str, duration_minutes: int) -> List[Dict]:
        """
        Create clips from Kick stream
        """
        logger.info(f"üü¢ KICK PROCESSING: {stream_url}")
        
        # Mock implementation for demo
        clips = []
        clips_needed = max(1, duration_minutes // 12)  # 1 clip per 12 minutes
        
        for i in range(clips_needed):
            await asyncio.sleep(0.4)
            
            clip = {
                "id": f"kick_clip_{i}_{int(time.time())}",
                "platform": "kick",
                "url": stream_url,
                "start_time": i * 720,  # 12 minutes apart
                "duration": min(720, (duration_minutes - i * 12) * 60),
                "created_at": datetime.now().isoformat(),
                "audio_file": await self._mock_extract_audio(stream_url, i)
            }
            clips.append(clip)
            logger.info(f"‚úÖ CLIP CREATED: {clip['id']} ({clip['duration']}s)")
        
        return clips
    
    async def _mock_extract_audio(self, stream_url: str, segment_index: int) -> str:
        """
        Mock audio extraction for demo purposes
        In production, this would use yt-dlp or direct stream extraction
        """
        # Create mock audio file path
        filename = f"mock_audio_{segment_index}_{int(time.time())}.wav"
        filepath = os.path.join(self.temp_dir, filename)
        
        # In production, this would contain actual audio extraction logic:
        # return await self._extract_audio_with_ytdlp(stream_url, start_time, duration)
        
        return filepath
    
    async def _extract_audio_with_ytdlp(self, stream_url: str, start_time: int, duration: int) -> str:
        """
        Real implementation using yt-dlp (commented for demo)
        """
        # This would be the production implementation:
        """
        output_filename = f"stream_audio_{int(time.time())}_{start_time}.wav"
        output_path = os.path.join(self.temp_dir, output_filename)
        
        # yt-dlp command to extract audio segment
        cmd = [
            'yt-dlp',
            '--extract-audio',
            '--audio-format', 'wav',
            '--audio-quality', '0',
            '--external-downloader', 'ffmpeg',
            '--external-downloader-args', 
            f'-ss {start_time} -t {duration}',
            '-o', output_path,
            stream_url
        ]
        
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            logger.error(f"yt-dlp failed: {stderr.decode()}")
            raise Exception(f"Audio extraction failed: {stderr.decode()}")
        
        return output_path
        """
        pass
    
    def cleanup_temp_files(self, clips: List[Dict]):
        """Clean up temporary audio files"""
        for clip in clips:
            audio_file = clip.get('audio_file')
            if audio_file and os.path.exists(audio_file):
                try:
                    os.remove(audio_file)
                    logger.info(f"üóëÔ∏è CLEANUP: Removed {audio_file}")
                except Exception as e:
                    logger.error(f"‚ùå CLEANUP FAILED: {audio_file} - {e}")

# Production implementation notes:
"""
For production deployment, this module would need:

1. Real yt-dlp integration:
   - Install yt-dlp and ffmpeg
   - Handle platform-specific authentication
   - Manage rate limits and retries

2. Twitch API integration:
   - OAuth token management
   - Clips API for programmatic clip creation
   - Handle API rate limits (800 requests/minute)

3. YouTube API integration:
   - YouTube Data API v3 for live stream info
   - Direct HLS stream access when possible

4. Error handling:
   - Platform-specific error codes
   - Fallback strategies for failed extractions
   - Retry logic with exponential backoff

5. Performance optimization:
   - Parallel download with connection pooling
   - Audio segment caching
   - Memory-efficient processing

6. Security:
   - Input validation for stream URLs
   - Secure temporary file handling
   - API key management
"""